{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-En0ARbCLP7E"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FewkTbmbD3GT",
        "outputId": "b4599e84-9531-493b-e5a9-6b27155e2ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running on the GPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"running on the CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6QU-uSFR6JA"
      },
      "source": [
        "# Knowledge Graph Embedding and Similar Fact Retrieval Using TransE and TransR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This project involves developing a custom implementation of two knowledge graph embedding techniques, TransE and TransR, to tackle key tasks in knowledge graph analysis. By integrating knowledge graph embedding techniques with real-world applications like question-answering and fact retrieval, the project aims to explore the utility and comparative performance of TransE and TransR in knowledge graph reasoning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy3390HYR_xC"
      },
      "source": [
        "# Dataset Description:\n",
        "Use the Nations and Kinships datasets for the 1-hop question-answering and Nations dataset for the\n",
        "similar fact retrieval task.\n",
        "Nations: The Nations dataset is a small knowledge graph with 14 entities, 55 relations, and 1992\n",
        "triples describing countries and their political relationships.\n",
        "Kinships:The Kinships dataset describes relationships between members of the Australian tribe\n",
        "Alyawarra and consists of 10,686 triples. It contains 104 entities representing members of the\n",
        "tribe and 26 relationship types that represent kinship terms such as Adiadya or Umbaidya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKCqkpjWRwT8"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqL90vzHSMCp"
      },
      "source": [
        "# Setup and Data Preprocessing (2 marks)\n",
        "● Install the pyKEEN library.\n",
        "\n",
        "● Load the datasets from the pyKEEN library extracting triples for training, validation and\n",
        "testing. (https://pykeen.readthedocs.io/en/stable/reference/datasets.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BVKW_3KvSNKj",
        "outputId": "a60a8607-7d50-4ab1-ee27-5c69d1a17ca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pykeen in /usr/local/lib/python3.10/dist-packages (1.11.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.6.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.13.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from pykeen) (8.1.7)\n",
            "Requirement already satisfied: click-default-group in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pykeen) (1.5.2)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pykeen) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pykeen) (2.32.3)\n",
            "Requirement already satisfied: optuna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (4.0.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pykeen) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.9.0)\n",
            "Requirement already satisfied: more-click in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.1.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from pykeen) (10.5.0)\n",
            "Requirement already satisfied: pystow>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.5.6)\n",
            "Requirement already satisfied: docdata in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.0.4)\n",
            "Requirement already satisfied: class-resolver>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.5.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pykeen) (6.0.2)\n",
            "Requirement already satisfied: torch-max-mem>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.1.3)\n",
            "Requirement already satisfied: torch-ppr>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pykeen) (0.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pykeen) (4.12.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (1.13.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen) (2.0.36)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->pykeen) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->pykeen) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->pykeen) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->pykeen) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0->pykeen) (1.3.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->pykeen) (3.23.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->pykeen) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pykeen) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pykeen) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pykeen) (3.5.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=2.0.0->pykeen) (1.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->pykeen) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=2.0.0->pykeen) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->pykeen) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pykeen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-CdHamozPeW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from pykeen import datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS5WxIGYvrv3"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "from pykeen import datasets #import pykeen as mentioned in question\n",
        "nations = datasets.Nations() #load nations dataset\n",
        "kinships = datasets.Kinships()# load kinships dataset\n",
        "\n",
        "#training triples\n",
        "nations_triples_training = nations.training.mapped_triples\n",
        "kinships_triples_training = kinships.training.mapped_triples\n",
        "\n",
        "#test triples\n",
        "nations_triples_test = nations.testing.mapped_triples\n",
        "kinships_triples_test = kinships.testing.mapped_triples\n",
        "\n",
        "#validation triples\n",
        "nations_triples_validation = nations.validation.mapped_triples\n",
        "kinships_triples_validation = kinships.validation.mapped_triples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_vlRoiR7x8xc"
      },
      "outputs": [],
      "source": [
        "# print(nations_triples_training)\n",
        "# print(kinships_triples_training)\n",
        "\n",
        "# print(nations_triples_test)\n",
        "# print(kinships_triples_test)\n",
        "\n",
        "# print(nations_triples_validation)\n",
        "# print(kinships_triples_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzPiOdFBSRkr"
      },
      "source": [
        "# TransE and TransR Implementation Specifications\n",
        "● Embedding Dimension: 100\n",
        "\n",
        "● Margin: Vary 1.0 to 5.0 with step size 1.0 for Nations dataset and take 1.0 for Kinships dataset.\n",
        "\n",
        "● Optimizer: Adam, learning rate 0.001, train for 50 epochs.\n",
        "\n",
        "● Use margin-based ranking loss.\n",
        "\n",
        "● Use Bernoulli Negative sampling (without using the built-in library function) for generating the negative samples.\n",
        "Refer:https://pykeen.readthedocs.io/en/stable/reference/negative_sampling.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2rn_sFdYf0C"
      },
      "outputs": [],
      "source": [
        "'''In the negative sampling function we are generating negative samples for a knowledge graph by corrupting either the head or tail of each positive sample.\n",
        "The corruption probability depends on the specific relation, defaulting to 0.5 if no relation-specific probability is given.\n",
        "The function returns a tensor of these negative samples, where each sample has either a corrupted head or tail.'''\n",
        "\n",
        "def bernoulli_negative_sampling(positive_samples, relation_probabilities, n_entities):\n",
        "    negative_samples = []#to store prob of negavtive samples\n",
        "    for h, r, t in positive_samples:#iterate over positive samples\n",
        "        pr = relation_probabilities.get(r.item(), 0.5)  # Default to 0.5 if not found\n",
        "        if np.random.rand() < pr:\n",
        "            # Head corruption\n",
        "            h_corrupt = np.random.randint(0, n_entities)#replace head with some randome entity\n",
        "            negative_samples.append([h_corrupt, r.item(), t.item()])\n",
        "        else:\n",
        "            # Tail corruption\n",
        "            t_corrupt = np.random.randint(0, n_entities)# replace tail with random entity\n",
        "            negative_samples.append([h.item(), r.item(), t_corrupt])\n",
        "    return torch.tensor(negative_samples, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xle3v-t-Ygvm"
      },
      "outputs": [],
      "source": [
        "# Implementation of TransE as asked in the question\n",
        "\n",
        "'''\n",
        "In this code we have implemented a TransE model for knowledge graph embeddings, where entities and relations are embedded in a space where relations are the translations.\n",
        "It computes scores based on the L2 distance between head + relation and tail embeddings, used for link prediction tasks.\n",
        "The predict method further calculates scores for every possible head or tail for each triplet in the batch, help to get head and tail prediction tasks.'''\n",
        "\n",
        "class TransE(nn.Module):\n",
        "    def __init__(self, n_entities, n_relations, embedding_dim):\n",
        "        super(TransE, self).__init__()\n",
        "\n",
        "        # Initialize entity and relation embeddings\n",
        "        self.entity_embedding = nn.Parameter(torch.randn(n_entities, embedding_dim))\n",
        "        self.relation_embedding = nn.Parameter(torch.randn(n_relations, embedding_dim))\n",
        "\n",
        "        # Set device to GPU if available\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.num_entities = n_entities\n",
        "\n",
        "        # Uniformly initialize embeddings in the range based on embedding dimension\n",
        "        nn.init.uniform_(self.entity_embedding, -6 / np.sqrt(embedding_dim), 6 / np.sqrt(embedding_dim))\n",
        "        nn.init.uniform_(self.relation_embedding, -6 / np.sqrt(embedding_dim), 6 / np.sqrt(embedding_dim))\n",
        "\n",
        "        # Normalize entity embeddings to unit length\n",
        "        self.entity_embedding.data = F.normalize(self.entity_embedding.data, p=2, dim=1)\n",
        "\n",
        "    def forward(self, samples):\n",
        "        # Get embeddings for heads, relations, and tails in the sample batch\n",
        "        h = self.entity_embedding[samples[:, 0]] #head entity realization\n",
        "        r = self.relation_embedding[samples[:, 1]] # relation entity realization\n",
        "        t = self.entity_embedding[samples[:, 2]] # tail entity realization\n",
        "\n",
        "        # Return negative L2 distance as score\n",
        "        return -torch.norm(h + r - t, p=2, dim=1)\n",
        "\n",
        "    def score(self, head, relation, tail):\n",
        "        #Compute the TransE score as the L2 distance\n",
        "        h = self.entity_embedding[head]\n",
        "        r = self.relation_embedding[relation]\n",
        "        t = self.entity_embedding[tail]\n",
        "\n",
        "        # Return negative L2 distance as score\n",
        "        return -torch.norm(h + r - t, p=2, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, batch): #Predicts scores for all possible heads and tails for each triple in the batch\n",
        "        heads = batch[:, 0]\n",
        "        relations = batch[:, 1]\n",
        "        tails = batch[:, 2]\n",
        "        batch_size = len(batch)\n",
        "\n",
        "        # Head prediction scores\n",
        "        all_entities = torch.arange(self.num_entities, device=self.device)\n",
        "        head_scores = [] #to store head scores\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            r = self.relation_embedding[relations[i]] #calc head relations\n",
        "            t = self.entity_embedding[tails[i]] #calc tail relations\n",
        "\n",
        "            # Calculate scores for all possible heads\n",
        "            candidate_heads = self.entity_embedding\n",
        "            scores = -torch.norm(candidate_heads + r - t, p=2, dim=1)\n",
        "            head_scores.append(scores)\n",
        "\n",
        "        head_scores = torch.stack(head_scores)\n",
        "\n",
        "        # Tail prediction scores\n",
        "        tail_scores = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            h = self.entity_embedding[heads[i]]\n",
        "            r = self.relation_embedding[relations[i]]\n",
        "\n",
        "            # Calculate scores for all possible tails\n",
        "            candidate_tails = self.entity_embedding\n",
        "            scores = -torch.norm(h + r - candidate_tails, p=2, dim=1)\n",
        "            tail_scores.append(scores)\n",
        "\n",
        "        tail_scores = torch.stack(tail_scores)\n",
        "\n",
        "        # Return stacked scores for head and tail predictions\n",
        "        return head_scores, tail_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntAMg-FhYkvp"
      },
      "outputs": [],
      "source": [
        "#implementing transR as mentioned in question\n",
        "'''In this code we implement the TransR model, which projects entities into relation-specific spaces to capture complex relational patterns in knowledge graphs.\n",
        " For each triplet, it computes scores using the L2 distance between projected entity embeddings and relation embeddings. An evaluation function calculates ranking metrics,\n",
        " like mean rank and Hits@10, to assess the model's performance on test data.'''\n",
        "\n",
        "class TransR(nn.Module):\n",
        "    def __init__(self, n_entities, n_relations, embedding_dim):\n",
        "        super(TransR, self).__init__()\n",
        "\n",
        "        # Initialize entity, relation embeddings and relation-specific projection matrices\n",
        "        self.entity_embedding = nn.Parameter(torch.randn(n_entities, embedding_dim))\n",
        "        self.relation_embedding = nn.Parameter(torch.randn(n_relations, embedding_dim))\n",
        "        self.relation_matrix = nn.Parameter(torch.randn(n_relations, embedding_dim, embedding_dim))\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.num_entities = n_entities\n",
        "\n",
        "        # Uniformly initialize embeddings and normalize entity embeddings\n",
        "        nn.init.uniform_(self.entity_embedding, -6 / np.sqrt(embedding_dim), 6 / np.sqrt(embedding_dim))\n",
        "        nn.init.uniform_(self.relation_embedding, -6 / np.sqrt(embedding_dim), 6 / np.sqrt(embedding_dim))\n",
        "        self.entity_embedding.data = F.normalize(self.entity_embedding.data, p=2, dim=1)\n",
        "\n",
        "    def forward(self, samples):\n",
        "        # Get embeddings for head, relation, and tail for each sample in batch\n",
        "        h = self.entity_embedding[samples[:, 0]]\n",
        "        r = self.relation_embedding[samples[:, 1]]\n",
        "        t = self.entity_embedding[samples[:, 2]]\n",
        "\n",
        "        # Get relation-specific projection matrix\n",
        "        W_r = self.relation_matrix[samples[:, 1]]\n",
        "\n",
        "        # Project entity embeddings into the relation-specific space\n",
        "        h_proj = torch.bmm(W_r, h.unsqueeze(-1)).squeeze(-1)\n",
        "        t_proj = torch.bmm(W_r, t.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        # Return negative L2 distance between projected head + relation and projected tail\n",
        "        return -torch.norm(h_proj + r - t_proj, p=2, dim=1)\n",
        "\n",
        "   #Predict scores for all possible heads and tails for each triple in the batch. Returns scores for head and tail prediction tasks.\n",
        "    def predict(self, batch):\n",
        "        heads = batch[:, 0]\n",
        "        relations = batch[:, 1]\n",
        "        tails = batch[:, 2]\n",
        "        batch_size = len(batch)\n",
        "\n",
        "        # Head prediction scores\n",
        "        head_scores = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Get relation and tail embeddings for the current triple\n",
        "            r = self.relation_embedding[relations[i]]\n",
        "            t = self.entity_embedding[tails[i]]\n",
        "            W_r = self.relation_matrix[relations[i]]\n",
        "\n",
        "            # Project all candidate heads\n",
        "            candidate_heads = self.entity_embedding\n",
        "            candidate_heads_proj = torch.mm(candidate_heads, W_r.t())  # (num_entities, dim)\n",
        "\n",
        "            # Project the tail\n",
        "            t_proj = torch.mv(W_r, t)\n",
        "\n",
        "            # Calculate scores for each candidate head\n",
        "            scores = -torch.norm(candidate_heads_proj + r - t_proj, p=2, dim=1)\n",
        "            head_scores.append(scores)\n",
        "\n",
        "        head_scores = torch.stack(head_scores)\n",
        "\n",
        "        # Tail prediction scores\n",
        "        tail_scores = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Get head and relation embeddings for the current triple\n",
        "            h = self.entity_embedding[heads[i]]\n",
        "            r = self.relation_embedding[relations[i]]\n",
        "            W_r = self.relation_matrix[relations[i]]\n",
        "\n",
        "            # Project the head\n",
        "            h_proj = torch.mv(W_r, h)\n",
        "\n",
        "            # Project all candidate tails\n",
        "            candidate_tails = self.entity_embedding\n",
        "            candidate_tails_proj = torch.mm(candidate_tails, W_r.t())\n",
        "\n",
        "            # Calculate scores for each candidate tail\n",
        "            scores = -torch.norm(h_proj + r - candidate_tails_proj, p=2, dim=1)\n",
        "            tail_scores.append(scores)\n",
        "\n",
        "        tail_scores = torch.stack(tail_scores)\n",
        "\n",
        "        # Return stacked scores for head and tail predictions\n",
        "        return head_scores, tail_scores\n",
        "\n",
        "def evaluate_model(model, test_triples, batch_size=128):#Evaluate the model using ranking metrics\n",
        "\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "\n",
        "    # Convert test triples to a tensor on the model's device\n",
        "    test_triples = torch.tensor(test_triples, dtype=torch.long, device=device)\n",
        "\n",
        "    # Initialize lists for storing ranks of correct heads and tails\n",
        "    head_ranks = []\n",
        "    tail_ranks = []\n",
        "\n",
        "    # Process test triples in batches\n",
        "    for i in tqdm(range(0, len(test_triples), batch_size)):\n",
        "        batch = test_triples[i:i + batch_size]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Predict scores for all candidate heads and tails\n",
        "            head_scores, tail_scores = model.predict(batch)\n",
        "\n",
        "            # Calculate ranks for head prediction\n",
        "            for j, triple in enumerate(batch):\n",
        "                true_head = triple[0].item()\n",
        "                head_score = head_scores[j]\n",
        "                head_rank = (head_score >= head_score[true_head]).sum().item()  # Rank of correct head\n",
        "                head_ranks.append(head_rank)\n",
        "\n",
        "                # Calculate ranks for tail prediction\n",
        "                true_tail = triple[2].item()\n",
        "                tail_score = tail_scores[j]\n",
        "                tail_rank = (tail_score >= tail_score[true_tail]).sum().item()  # Rank of correct tail\n",
        "                tail_ranks.append(tail_rank)\n",
        "\n",
        "    # Convert ranks to tensors for metric calculation\n",
        "    head_ranks = torch.tensor(head_ranks)\n",
        "    tail_ranks = torch.tensor(tail_ranks)\n",
        "    all_ranks = torch.cat([head_ranks, tail_ranks])\n",
        "\n",
        "    # Calculate and return evaluation metrics\n",
        "    results = {\n",
        "        'mean_rank': float(all_ranks.float().mean()),# Calculate the mean rank of all predictions\n",
        "        'hits@10': float((all_ranks <= 10).float().mean()), # Calculate the percentage of predictions that hit within the top 10\n",
        "        'head_mean_rank': float(head_ranks.float().mean()), # Calculate the mean rank specifically for head predictions\n",
        "        'head_hits@10': float((head_ranks <= 10).float().mean()), # Calculate the percentage of head predictions hitting within the top 10\n",
        "        'tail_mean_rank': float(tail_ranks.float().mean()), # Calculate the mean rank specifically for tail predictions\n",
        "        'tail_hits@10': float((tail_ranks <= 10).float().mean()), # Calculate the percentage of tail predictions hitting within the top 10\n",
        "    }\n",
        "\n",
        "    return results #return results metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyZW_t4IYmXL"
      },
      "outputs": [],
      "source": [
        "def margin_ranking_loss(pos_score, neg_score, margin):\n",
        "    return torch.mean(F.relu(pos_score - neg_score + margin))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfL04tCUYove"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, optimizer, margin, relation_probabilities, n_entities, epochs=50):\n",
        "    model.train()\n",
        "    loss_inall = 0\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for positive_samples in data_loader:\n",
        "            # Generate negative samples using Bernoulli sampling\n",
        "            negative_samples = bernoulli_negative_sampling(positive_samples, relation_probabilities, n_entities)\n",
        "\n",
        "            # Compute positive and negative scores\n",
        "            pos_score = model(positive_samples)\n",
        "            neg_score = model(negative_samples)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = margin_ranking_loss(pos_score, neg_score, margin)\n",
        "\n",
        "            # Backpropagation and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()#backpropagate\n",
        "            optimizer.step()\n",
        "            # loss calculating\n",
        "            total_loss += loss.item()\n",
        "            loss_inall = loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "    return loss_inall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmrv1iVrz26D"
      },
      "outputs": [],
      "source": [
        "def compute_relation_probabilities(triples, n_relations):\n",
        "    # Initialize counters for head occurrences and total occurrences per relation\n",
        "    head_counts = torch.zeros(n_relations)\n",
        "    total_counts = torch.zeros(n_relations)\n",
        "\n",
        "    # Count heads and total occurrences for each relation in the triples\n",
        "    for h, r, t in triples:\n",
        "        head_counts[r] += 1  # Increment head count for the relation\n",
        "        total_counts[r] += 1  # Increment total count for the relation\n",
        "\n",
        "    # Calculate the probability of head corruption for each relation\n",
        "    return {r: (head_counts[r] / total_counts[r]).item() for r in range(n_relations)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2FvgWfJYwrG",
        "outputId": "c000489f-f6dd-4b15-f7b7-d468f63447c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 48.9494\n",
            "Epoch 2/50, Loss: 48.0485\n",
            "Epoch 3/50, Loss: 47.5442\n",
            "Epoch 4/50, Loss: 46.1430\n",
            "Epoch 5/50, Loss: 45.3785\n",
            "Epoch 6/50, Loss: 44.1332\n",
            "Epoch 7/50, Loss: 43.9247\n",
            "Epoch 8/50, Loss: 42.1868\n",
            "Epoch 9/50, Loss: 41.3695\n",
            "Epoch 10/50, Loss: 40.7565\n",
            "Epoch 11/50, Loss: 40.7313\n",
            "Epoch 12/50, Loss: 39.0104\n",
            "Epoch 13/50, Loss: 39.1957\n",
            "Epoch 14/50, Loss: 38.7977\n",
            "Epoch 15/50, Loss: 38.3225\n",
            "Epoch 16/50, Loss: 38.4224\n",
            "Epoch 17/50, Loss: 38.0612\n",
            "Epoch 18/50, Loss: 37.3143\n",
            "Epoch 19/50, Loss: 37.5098\n",
            "Epoch 20/50, Loss: 37.4815\n",
            "Epoch 21/50, Loss: 36.0952\n",
            "Epoch 22/50, Loss: 35.4031\n",
            "Epoch 23/50, Loss: 35.9299\n",
            "Epoch 24/50, Loss: 35.6815\n",
            "Epoch 25/50, Loss: 35.5254\n",
            "Epoch 26/50, Loss: 35.3962\n",
            "Epoch 27/50, Loss: 35.1094\n",
            "Epoch 28/50, Loss: 34.9971\n",
            "Epoch 29/50, Loss: 34.5002\n",
            "Epoch 30/50, Loss: 33.8469\n",
            "Epoch 31/50, Loss: 34.7669\n",
            "Epoch 32/50, Loss: 34.1896\n",
            "Epoch 33/50, Loss: 35.1080\n",
            "Epoch 34/50, Loss: 35.7193\n",
            "Epoch 35/50, Loss: 34.4077\n",
            "Epoch 36/50, Loss: 33.4500\n",
            "Epoch 37/50, Loss: 34.2212\n",
            "Epoch 38/50, Loss: 34.1066\n",
            "Epoch 39/50, Loss: 34.7937\n",
            "Epoch 40/50, Loss: 34.0054\n",
            "Epoch 41/50, Loss: 33.3806\n",
            "Epoch 42/50, Loss: 33.5740\n",
            "Epoch 43/50, Loss: 34.2090\n",
            "Epoch 44/50, Loss: 33.2111\n",
            "Epoch 45/50, Loss: 32.6972\n",
            "Epoch 46/50, Loss: 33.9570\n",
            "Epoch 47/50, Loss: 33.1140\n",
            "Epoch 48/50, Loss: 33.5446\n",
            "Epoch 49/50, Loss: 35.5335\n",
            "Epoch 50/50, Loss: 33.6810\n",
            "Epoch 1/50, Loss: 77.1968\n",
            "Epoch 2/50, Loss: 74.7176\n",
            "Epoch 3/50, Loss: 75.4534\n",
            "Epoch 4/50, Loss: 73.6006\n",
            "Epoch 5/50, Loss: 74.3245\n",
            "Epoch 6/50, Loss: 73.2694\n",
            "Epoch 7/50, Loss: 75.4818\n",
            "Epoch 8/50, Loss: 72.2124\n",
            "Epoch 9/50, Loss: 71.3526\n",
            "Epoch 10/50, Loss: 71.6931\n",
            "Epoch 11/50, Loss: 70.4591\n",
            "Epoch 12/50, Loss: 70.3206\n",
            "Epoch 13/50, Loss: 69.0985\n",
            "Epoch 14/50, Loss: 72.0777\n",
            "Epoch 15/50, Loss: 71.0742\n",
            "Epoch 16/50, Loss: 70.3514\n",
            "Epoch 17/50, Loss: 70.1111\n",
            "Epoch 18/50, Loss: 70.8157\n",
            "Epoch 19/50, Loss: 70.7062\n",
            "Epoch 20/50, Loss: 69.9918\n",
            "Epoch 21/50, Loss: 71.3131\n",
            "Epoch 22/50, Loss: 69.9089\n",
            "Epoch 23/50, Loss: 70.1090\n",
            "Epoch 24/50, Loss: 69.6248\n",
            "Epoch 25/50, Loss: 69.7240\n",
            "Epoch 26/50, Loss: 71.5744\n",
            "Epoch 27/50, Loss: 69.3792\n",
            "Epoch 28/50, Loss: 70.1149\n",
            "Epoch 29/50, Loss: 66.9551\n",
            "Epoch 30/50, Loss: 69.4135\n",
            "Epoch 31/50, Loss: 69.3751\n",
            "Epoch 32/50, Loss: 66.6906\n",
            "Epoch 33/50, Loss: 68.3243\n",
            "Epoch 34/50, Loss: 70.0535\n",
            "Epoch 35/50, Loss: 68.8377\n",
            "Epoch 36/50, Loss: 68.3902\n",
            "Epoch 37/50, Loss: 67.4258\n",
            "Epoch 38/50, Loss: 68.2647\n",
            "Epoch 39/50, Loss: 68.5698\n",
            "Epoch 40/50, Loss: 67.8603\n",
            "Epoch 41/50, Loss: 69.9293\n",
            "Epoch 42/50, Loss: 66.9451\n",
            "Epoch 43/50, Loss: 67.5592\n",
            "Epoch 44/50, Loss: 65.7577\n",
            "Epoch 45/50, Loss: 67.3338\n",
            "Epoch 46/50, Loss: 68.5177\n",
            "Epoch 47/50, Loss: 66.2256\n",
            "Epoch 48/50, Loss: 64.2928\n",
            "Epoch 49/50, Loss: 66.2338\n",
            "Epoch 50/50, Loss: 67.7113\n",
            "Epoch 1/50, Loss: 111.5893\n",
            "Epoch 2/50, Loss: 108.4927\n",
            "Epoch 3/50, Loss: 106.0318\n",
            "Epoch 4/50, Loss: 108.1902\n",
            "Epoch 5/50, Loss: 110.2852\n",
            "Epoch 6/50, Loss: 108.7224\n",
            "Epoch 7/50, Loss: 108.0314\n",
            "Epoch 8/50, Loss: 109.2494\n",
            "Epoch 9/50, Loss: 106.1574\n",
            "Epoch 10/50, Loss: 104.1697\n",
            "Epoch 11/50, Loss: 109.5277\n",
            "Epoch 12/50, Loss: 105.7061\n",
            "Epoch 13/50, Loss: 106.8162\n",
            "Epoch 14/50, Loss: 107.5334\n",
            "Epoch 15/50, Loss: 106.3405\n",
            "Epoch 16/50, Loss: 107.3136\n",
            "Epoch 17/50, Loss: 104.3971\n",
            "Epoch 18/50, Loss: 106.8735\n",
            "Epoch 19/50, Loss: 103.7753\n",
            "Epoch 20/50, Loss: 104.5160\n",
            "Epoch 21/50, Loss: 105.7952\n",
            "Epoch 22/50, Loss: 104.9819\n",
            "Epoch 23/50, Loss: 105.0988\n",
            "Epoch 24/50, Loss: 106.3650\n",
            "Epoch 25/50, Loss: 105.8460\n",
            "Epoch 26/50, Loss: 105.5383\n",
            "Epoch 27/50, Loss: 103.5225\n",
            "Epoch 28/50, Loss: 104.8396\n",
            "Epoch 29/50, Loss: 101.9934\n",
            "Epoch 30/50, Loss: 106.2263\n",
            "Epoch 31/50, Loss: 104.4554\n",
            "Epoch 32/50, Loss: 104.6448\n",
            "Epoch 33/50, Loss: 107.2545\n",
            "Epoch 34/50, Loss: 106.0257\n",
            "Epoch 35/50, Loss: 105.7437\n",
            "Epoch 36/50, Loss: 103.6860\n",
            "Epoch 37/50, Loss: 102.8727\n",
            "Epoch 38/50, Loss: 103.8528\n",
            "Epoch 39/50, Loss: 100.3608\n",
            "Epoch 40/50, Loss: 104.2911\n",
            "Epoch 41/50, Loss: 104.4614\n",
            "Epoch 42/50, Loss: 104.2762\n",
            "Epoch 43/50, Loss: 102.4956\n",
            "Epoch 44/50, Loss: 105.4457\n",
            "Epoch 45/50, Loss: 102.7623\n",
            "Epoch 46/50, Loss: 104.2871\n",
            "Epoch 47/50, Loss: 103.4057\n",
            "Epoch 48/50, Loss: 103.7067\n",
            "Epoch 49/50, Loss: 102.9570\n",
            "Epoch 50/50, Loss: 102.6946\n",
            "Epoch 1/50, Loss: 144.1630\n",
            "Epoch 2/50, Loss: 146.1603\n",
            "Epoch 3/50, Loss: 140.6381\n",
            "Epoch 4/50, Loss: 143.9701\n",
            "Epoch 5/50, Loss: 144.2501\n",
            "Epoch 6/50, Loss: 140.0974\n",
            "Epoch 7/50, Loss: 143.6270\n",
            "Epoch 8/50, Loss: 143.5008\n",
            "Epoch 9/50, Loss: 145.6458\n",
            "Epoch 10/50, Loss: 142.3905\n",
            "Epoch 11/50, Loss: 141.6871\n",
            "Epoch 12/50, Loss: 142.7689\n",
            "Epoch 13/50, Loss: 137.4643\n",
            "Epoch 14/50, Loss: 141.3724\n",
            "Epoch 15/50, Loss: 142.9243\n",
            "Epoch 16/50, Loss: 141.2951\n",
            "Epoch 17/50, Loss: 141.2138\n",
            "Epoch 18/50, Loss: 141.3347\n",
            "Epoch 19/50, Loss: 142.7388\n",
            "Epoch 20/50, Loss: 138.3524\n",
            "Epoch 21/50, Loss: 141.4619\n",
            "Epoch 22/50, Loss: 140.5864\n",
            "Epoch 23/50, Loss: 141.7228\n",
            "Epoch 24/50, Loss: 141.4415\n",
            "Epoch 25/50, Loss: 140.5101\n",
            "Epoch 26/50, Loss: 138.8933\n",
            "Epoch 27/50, Loss: 138.9668\n",
            "Epoch 28/50, Loss: 138.1244\n",
            "Epoch 29/50, Loss: 140.2612\n",
            "Epoch 30/50, Loss: 138.8231\n",
            "Epoch 31/50, Loss: 142.0210\n",
            "Epoch 32/50, Loss: 135.5089\n",
            "Epoch 33/50, Loss: 140.3353\n",
            "Epoch 34/50, Loss: 138.9597\n",
            "Epoch 35/50, Loss: 139.2611\n",
            "Epoch 36/50, Loss: 135.9467\n",
            "Epoch 37/50, Loss: 141.2437\n",
            "Epoch 38/50, Loss: 137.3935\n",
            "Epoch 39/50, Loss: 139.7820\n",
            "Epoch 40/50, Loss: 140.5999\n",
            "Epoch 41/50, Loss: 136.3490\n",
            "Epoch 42/50, Loss: 139.2385\n",
            "Epoch 43/50, Loss: 136.8806\n",
            "Epoch 44/50, Loss: 139.9685\n",
            "Epoch 45/50, Loss: 136.8836\n",
            "Epoch 46/50, Loss: 134.0648\n",
            "Epoch 47/50, Loss: 136.5400\n",
            "Epoch 48/50, Loss: 137.6961\n",
            "Epoch 49/50, Loss: 140.9097\n",
            "Epoch 50/50, Loss: 140.0791\n",
            "Epoch 1/50, Loss: 179.2231\n",
            "Epoch 2/50, Loss: 176.9353\n",
            "Epoch 3/50, Loss: 177.5535\n",
            "Epoch 4/50, Loss: 176.9359\n",
            "Epoch 5/50, Loss: 178.1801\n",
            "Epoch 6/50, Loss: 183.4189\n",
            "Epoch 7/50, Loss: 178.9148\n",
            "Epoch 8/50, Loss: 181.4582\n",
            "Epoch 9/50, Loss: 178.7012\n",
            "Epoch 10/50, Loss: 179.9924\n",
            "Epoch 11/50, Loss: 176.5746\n",
            "Epoch 12/50, Loss: 171.2677\n",
            "Epoch 13/50, Loss: 173.4934\n",
            "Epoch 14/50, Loss: 178.0095\n",
            "Epoch 15/50, Loss: 175.7258\n",
            "Epoch 16/50, Loss: 175.4089\n",
            "Epoch 17/50, Loss: 173.4063\n",
            "Epoch 18/50, Loss: 177.5785\n",
            "Epoch 19/50, Loss: 178.9079\n",
            "Epoch 20/50, Loss: 177.3651\n",
            "Epoch 21/50, Loss: 179.2015\n",
            "Epoch 22/50, Loss: 179.2609\n",
            "Epoch 23/50, Loss: 173.6163\n",
            "Epoch 24/50, Loss: 177.4926\n",
            "Epoch 25/50, Loss: 173.5972\n",
            "Epoch 26/50, Loss: 171.0169\n",
            "Epoch 27/50, Loss: 176.6527\n",
            "Epoch 28/50, Loss: 174.6205\n",
            "Epoch 29/50, Loss: 174.4682\n",
            "Epoch 30/50, Loss: 171.8877\n",
            "Epoch 31/50, Loss: 175.8573\n",
            "Epoch 32/50, Loss: 173.8532\n",
            "Epoch 33/50, Loss: 176.0652\n",
            "Epoch 34/50, Loss: 176.4826\n",
            "Epoch 35/50, Loss: 177.1351\n",
            "Epoch 36/50, Loss: 172.5677\n",
            "Epoch 37/50, Loss: 175.5694\n",
            "Epoch 38/50, Loss: 174.9855\n",
            "Epoch 39/50, Loss: 172.4283\n",
            "Epoch 40/50, Loss: 172.3464\n",
            "Epoch 41/50, Loss: 176.0184\n",
            "Epoch 42/50, Loss: 170.7081\n",
            "Epoch 43/50, Loss: 174.4859\n",
            "Epoch 44/50, Loss: 168.4337\n",
            "Epoch 45/50, Loss: 174.6796\n",
            "Epoch 46/50, Loss: 174.9884\n",
            "Epoch 47/50, Loss: 172.6896\n",
            "Epoch 48/50, Loss: 176.5747\n",
            "Epoch 49/50, Loss: 171.4884\n",
            "Epoch 50/50, Loss: 171.2922\n",
            "Best margin value: 1\n",
            "Best loss value: 0.6393926739692688\n"
          ]
        }
      ],
      "source": [
        "'''Here we are training a TransE model on the Nations dataset, iterating over different margin values (1 to 5) to find the best-performing one based on loss.\n",
        "For each margin, the code trains the model, evaluates its loss, and updates the best margin and model if a lower loss is achieved.\n",
        "Finally, it outputs the optimal margin and the corresponding best loss value.\n",
        "'''\n",
        "from torch.utils.data import DataLoader\n",
        "# Get the number of entities and relations from the Nations dataset\n",
        "n_entities = nations.num_entities\n",
        "n_relations = nations.num_relations\n",
        "embedding_dim = 100  # Set embedding dimension to 100\n",
        "margin = 1.0\n",
        "learning_rate = 0.001\n",
        "batch_size = 32 #at once 32 samples processed\n",
        "\n",
        "\n",
        "best_loss_value = float('inf')#high upper bound\n",
        "best_margin = None\n",
        "best_model = None#initially none\n",
        "\n",
        "# Prepare DataLoader\n",
        "nations_loader = DataLoader(nations_triples_training, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize E_nationsmodel, optimizer, and relation probabilities\n",
        "E_nationsmodel = TransE(n_entities, n_relations, embedding_dim)\n",
        "optimizer = torch.optim.Adam(E_nationsmodel.parameters(), lr=learning_rate)\n",
        "relation_probabilities = compute_relation_probabilities(nations_triples_training, n_relations)\n",
        "\n",
        "# Train the E_nationsmodel on Nations dataset for range of margin values\n",
        "for margin in range(1,6):\n",
        "  lossvalue = train(E_nationsmodel, nations_loader, optimizer, margin, relation_probabilities, n_entities, epochs=50)\n",
        "  if lossvalue < best_loss_value:# a lower loss received\n",
        "    best_loss_value = lossvalue#updatations\n",
        "    best_margin = margin\n",
        "    best_model = E_nationsmodel\n",
        "#print best parameters of the model\n",
        "print(f\"Best margin value: {best_margin}\")\n",
        "print(f\"Best loss value: {best_loss_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_CHi9SHVYEw",
        "outputId": "55538795-bbb3-4fa5-8f60-e2da26387e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 55.9754\n",
            "Epoch 2/50, Loss: 46.9665\n",
            "Epoch 3/50, Loss: 42.8714\n",
            "Epoch 4/50, Loss: 39.2817\n",
            "Epoch 5/50, Loss: 36.6411\n",
            "Epoch 6/50, Loss: 34.0872\n",
            "Epoch 7/50, Loss: 32.3795\n",
            "Epoch 8/50, Loss: 32.3543\n",
            "Epoch 9/50, Loss: 30.3523\n",
            "Epoch 10/50, Loss: 28.2040\n",
            "Epoch 11/50, Loss: 26.9658\n",
            "Epoch 12/50, Loss: 28.5615\n",
            "Epoch 13/50, Loss: 27.5456\n",
            "Epoch 14/50, Loss: 27.4084\n",
            "Epoch 15/50, Loss: 28.3215\n",
            "Epoch 16/50, Loss: 26.0162\n",
            "Epoch 17/50, Loss: 27.2638\n",
            "Epoch 18/50, Loss: 25.8016\n",
            "Epoch 19/50, Loss: 26.0466\n",
            "Epoch 20/50, Loss: 27.0507\n",
            "Epoch 21/50, Loss: 24.3653\n",
            "Epoch 22/50, Loss: 26.3634\n",
            "Epoch 23/50, Loss: 24.5168\n",
            "Epoch 24/50, Loss: 26.1413\n",
            "Epoch 25/50, Loss: 24.9471\n",
            "Epoch 26/50, Loss: 25.3321\n",
            "Epoch 27/50, Loss: 23.8930\n",
            "Epoch 28/50, Loss: 25.6216\n",
            "Epoch 29/50, Loss: 23.2272\n",
            "Epoch 30/50, Loss: 24.5460\n",
            "Epoch 31/50, Loss: 25.9844\n",
            "Epoch 32/50, Loss: 24.8679\n",
            "Epoch 33/50, Loss: 25.3468\n",
            "Epoch 34/50, Loss: 25.2792\n",
            "Epoch 35/50, Loss: 25.5992\n",
            "Epoch 36/50, Loss: 24.2018\n",
            "Epoch 37/50, Loss: 24.9616\n",
            "Epoch 38/50, Loss: 24.2990\n",
            "Epoch 39/50, Loss: 23.2788\n",
            "Epoch 40/50, Loss: 23.2369\n",
            "Epoch 41/50, Loss: 24.2086\n",
            "Epoch 42/50, Loss: 22.7424\n",
            "Epoch 43/50, Loss: 24.3447\n",
            "Epoch 44/50, Loss: 24.3734\n",
            "Epoch 45/50, Loss: 23.5308\n",
            "Epoch 46/50, Loss: 23.8809\n",
            "Epoch 47/50, Loss: 24.1813\n",
            "Epoch 48/50, Loss: 24.1414\n",
            "Epoch 49/50, Loss: 24.1088\n",
            "Epoch 50/50, Loss: 23.6554\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5061551332473755"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''IN this code  we train a TransR model on the Nations dataset using a predefined margin value of 1.\n",
        "It initializes the model, optimizer, and computes relation probabilities before training the model over 50 epochs.\n",
        "The DataLoader processes batches of training triples, and the train function updates model parameters to minimize loss.'''\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "# Get the number of entities and relations from the Nations dataset\n",
        "n_entities = nations.num_entities\n",
        "n_relations = nations.num_relations\n",
        "embedding_dim = 100  # Set embedding dimension to 100\n",
        "margin = 1.0  # best margin value is 1\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "\n",
        "# Prepare DataLoader\n",
        "nations_loader = DataLoader(nations_triples_training, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize R_nationsmodel, optimizer, and relation probabilities\n",
        "R_nationsmodel = TransR(n_entities, n_relations, embedding_dim)\n",
        "optimizer = torch.optim.Adam(R_nationsmodel.parameters(), lr=learning_rate) #initialise the optimiser\n",
        "relation_probabilities = compute_relation_probabilities(nations_triples_training, n_relations) #compute probabilities\n",
        "\n",
        "# Train the R_nationsmodel on Nations dataset\n",
        "train(R_nationsmodel, nations_loader, optimizer, margin, relation_probabilities, n_entities, epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GdEkIra2cl5",
        "outputId": "19b25cf2-fcda-4580-c04c-5b184bd310fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8544, 3])\n"
          ]
        }
      ],
      "source": [
        "print(kinships_triples_training.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6iBE1RM1XXr",
        "outputId": "4e8400e3-8138-42be-e058-40f0c659a084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 263.6979\n",
            "Epoch 2/50, Loss: 253.8918\n",
            "Epoch 3/50, Loss: 244.0318\n",
            "Epoch 4/50, Loss: 232.1162\n",
            "Epoch 5/50, Loss: 221.9679\n",
            "Epoch 6/50, Loss: 211.4868\n",
            "Epoch 7/50, Loss: 205.5587\n",
            "Epoch 8/50, Loss: 197.6220\n",
            "Epoch 9/50, Loss: 194.6723\n",
            "Epoch 10/50, Loss: 193.2817\n",
            "Epoch 11/50, Loss: 190.1415\n",
            "Epoch 12/50, Loss: 188.2780\n",
            "Epoch 13/50, Loss: 184.6678\n",
            "Epoch 14/50, Loss: 182.6369\n",
            "Epoch 15/50, Loss: 183.1060\n",
            "Epoch 16/50, Loss: 181.0164\n",
            "Epoch 17/50, Loss: 181.3415\n",
            "Epoch 18/50, Loss: 178.7636\n",
            "Epoch 19/50, Loss: 178.2701\n",
            "Epoch 20/50, Loss: 176.7388\n",
            "Epoch 21/50, Loss: 176.9328\n",
            "Epoch 22/50, Loss: 174.3738\n",
            "Epoch 23/50, Loss: 176.2237\n",
            "Epoch 24/50, Loss: 175.0438\n",
            "Epoch 25/50, Loss: 171.3251\n",
            "Epoch 26/50, Loss: 170.1950\n",
            "Epoch 27/50, Loss: 171.6785\n",
            "Epoch 28/50, Loss: 171.0599\n",
            "Epoch 29/50, Loss: 170.3238\n",
            "Epoch 30/50, Loss: 170.2756\n",
            "Epoch 31/50, Loss: 170.4719\n",
            "Epoch 32/50, Loss: 169.0198\n",
            "Epoch 33/50, Loss: 168.9116\n",
            "Epoch 34/50, Loss: 167.7375\n",
            "Epoch 35/50, Loss: 166.5412\n",
            "Epoch 36/50, Loss: 167.6890\n",
            "Epoch 37/50, Loss: 165.5206\n",
            "Epoch 38/50, Loss: 166.3176\n",
            "Epoch 39/50, Loss: 166.0432\n",
            "Epoch 40/50, Loss: 163.6271\n",
            "Epoch 41/50, Loss: 163.7622\n",
            "Epoch 42/50, Loss: 159.6631\n",
            "Epoch 43/50, Loss: 160.0845\n",
            "Epoch 44/50, Loss: 160.0170\n",
            "Epoch 45/50, Loss: 160.6679\n",
            "Epoch 46/50, Loss: 160.9136\n",
            "Epoch 47/50, Loss: 158.4975\n",
            "Epoch 48/50, Loss: 160.0277\n",
            "Epoch 49/50, Loss: 158.6682\n",
            "Epoch 50/50, Loss: 160.0457\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5764704942703247"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the number of entities and relations from the Kinships dataset\n",
        "n_entities = kinships.num_entities\n",
        "n_relations = kinships.num_relations\n",
        "embedding_dim = 100  # Set embedding dimension to 100\n",
        "margin = 1.0  # Margin for the loss function\n",
        "learning_rate = 0.001  # Learning rate for the optimizer\n",
        "batch_size = 32  # Batch size for DataLoader\n",
        "\n",
        "# Prepare DataLoader for Kinships training triples\n",
        "kinships_loader = DataLoader(kinships_triples_training, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize TransE model, optimizer, and relation probabilities\n",
        "E_kinshipmodel = TransE(n_entities, n_relations, embedding_dim)\n",
        "optimizer = torch.optim.Adam(E_kinshipmodel.parameters(), lr=learning_rate)\n",
        "relation_probabilities = compute_relation_probabilities(kinships_triples_training, n_relations)\n",
        "\n",
        "# Train the TransE model on the Kinships dataset for 50 epochs\n",
        "train(E_kinshipmodel, kinships_loader, optimizer, margin, relation_probabilities, n_entities, epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-IshxwEOTLP",
        "outputId": "ff14245f-9a3c-49c2-e827-6f86fd34424a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 326.4344\n",
            "Epoch 2/50, Loss: 268.7241\n",
            "Epoch 3/50, Loss: 228.2500\n",
            "Epoch 4/50, Loss: 190.5106\n",
            "Epoch 5/50, Loss: 161.9893\n",
            "Epoch 6/50, Loss: 140.1418\n",
            "Epoch 7/50, Loss: 120.1970\n",
            "Epoch 8/50, Loss: 112.6923\n",
            "Epoch 9/50, Loss: 101.5479\n",
            "Epoch 10/50, Loss: 86.9151\n",
            "Epoch 11/50, Loss: 83.5467\n",
            "Epoch 12/50, Loss: 78.6344\n",
            "Epoch 13/50, Loss: 76.2013\n",
            "Epoch 14/50, Loss: 73.8067\n",
            "Epoch 15/50, Loss: 69.8241\n",
            "Epoch 16/50, Loss: 67.4735\n",
            "Epoch 17/50, Loss: 66.7506\n",
            "Epoch 18/50, Loss: 64.2659\n",
            "Epoch 19/50, Loss: 66.0491\n",
            "Epoch 20/50, Loss: 62.3167\n",
            "Epoch 21/50, Loss: 59.2053\n",
            "Epoch 22/50, Loss: 63.3193\n",
            "Epoch 23/50, Loss: 61.6860\n",
            "Epoch 24/50, Loss: 57.2732\n",
            "Epoch 25/50, Loss: 60.1951\n",
            "Epoch 26/50, Loss: 56.7164\n",
            "Epoch 27/50, Loss: 55.3157\n",
            "Epoch 28/50, Loss: 58.7955\n",
            "Epoch 29/50, Loss: 54.6701\n",
            "Epoch 30/50, Loss: 57.2439\n",
            "Epoch 31/50, Loss: 54.1037\n",
            "Epoch 32/50, Loss: 55.1548\n",
            "Epoch 33/50, Loss: 55.4377\n",
            "Epoch 34/50, Loss: 53.0459\n",
            "Epoch 35/50, Loss: 52.3255\n",
            "Epoch 36/50, Loss: 52.9830\n",
            "Epoch 37/50, Loss: 54.0264\n",
            "Epoch 38/50, Loss: 53.9167\n",
            "Epoch 39/50, Loss: 53.3573\n",
            "Epoch 40/50, Loss: 52.7427\n",
            "Epoch 41/50, Loss: 50.5579\n",
            "Epoch 42/50, Loss: 51.6877\n",
            "Epoch 43/50, Loss: 52.4953\n",
            "Epoch 44/50, Loss: 53.1280\n",
            "Epoch 45/50, Loss: 50.5778\n",
            "Epoch 46/50, Loss: 49.4702\n",
            "Epoch 47/50, Loss: 52.9999\n",
            "Epoch 48/50, Loss: 50.7131\n",
            "Epoch 49/50, Loss: 50.7605\n",
            "Epoch 50/50, Loss: 51.8429\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.06686681509017944"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the number of entities and relations from the Kinships dataset\n",
        "n_entities = kinships.num_entities  # Number of unique entities in the dataset\n",
        "n_relations = kinships.num_relations  # Number of unique relations in the dataset\n",
        "\n",
        "embedding_dim = 100  # Set embedding dimension to 100\n",
        "margin = 1.0  # Set margin value for the training loss\n",
        "learning_rate = 0.001  # Set the learning rate for the optimizer\n",
        "batch_size = 32  # Set the number of samples per batch for training\n",
        "\n",
        "# Prepare DataLoader for Kinships training triples\n",
        "kinships_loader = DataLoader(kinships_triples_training, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize the TransR model with the specified parameters\n",
        "R_kinshipmodel = TransR(n_entities, n_relations, embedding_dim)\n",
        "\n",
        "# Create an Adam optimizer for the model's parameters\n",
        "optimizer = torch.optim.Adam(R_kinshipmodel.parameters(), lr=learning_rate)\n",
        "\n",
        "# Compute relation probabilities based on the training data\n",
        "relation_probabilities = compute_relation_probabilities(kinships_triples_training, n_relations)\n",
        "\n",
        "# Train the TransR model using the prepared DataLoader and specified parameters\n",
        "train(R_kinshipmodel, kinships_loader, optimizer, margin, relation_probabilities, n_entities, epochs=50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnPNCE1YSqzn"
      },
      "source": [
        "# 1-hop question-answering\n",
        "● For each triplet in the test set, perform head and tail prediction:\n",
        "\n",
        "  ○ Head Prediction: Replace the head entity with all possible entities and rank the scores. [Example: Given the triple (?, hasCapital, France), if we replace ?(head) with possible entities: London, Berlin, Paris, Madrid. The model should predict the correct head as Paris.]\n",
        "  ○ Tail Prediction: Replace the tail entity with all possible entities and rank the scores. [Example: Given the triple (Paris, hasCapital, ?), if we replace ? (tail) with possible entities: France, Germany, Spain, UK. The model should predict the correct tail as France.]\n",
        "● Compute ranking metrics for each prediction.\n",
        "\n",
        "● Overall Evaluation:\n",
        "\n",
        "  ○ Use the RankBasedEvaluator from\n",
        "  https://pykeen.readthedocs.io/en/latest/api/pykeen.evaluation.RankBasedEvaluator.html to obtain the metrics as follows:-\n",
        "  ■ Mean Rank (MR): Average rank of the correct entity.\n",
        "  ■ Hits@10: Proportion of correct entities ranked in the top 10\n",
        "  ■ Compare the performance of TransE and TransR based on these metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByBgw8Ip3JGt"
      },
      "source": [
        "Testing on Nations dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63SDKz1n3d2W",
        "outputId": "5c440766-00c2-4226-f392-beb105301d8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([201, 3])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nations_triples_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-00VAgz4TjST"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "i1RfPNlJ6Fxq",
        "outputId": "15460af9-ba67-4048-d1bd-9ffee36caa83"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  Decided to implement Mean Rank and Hits@10 from scratch instead of using the pykeen library.\\n  As pykeen library evaluate function requires a wrapped torch model implementation of TransE and TransR with different attributes and methods like eval, predict.\\n  So I have direclty iplemented the evaluation function from scratch.\\n\\n'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "  Decided to implement Mean Rank and Hits@10 from scratch instead of using the pykeen library.\n",
        "  As pykeen library evaluate function requires a wrapped torch model implementation of TransE and TransR with different attributes and methods like eval, predict.\n",
        "  So I have direclty iplemented the evaluation function from scratch.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvLwPd_5SYwz"
      },
      "outputs": [],
      "source": [
        "'''Here our code evaluates a knowledge graph embedding model by calculating ranking metrics such as Mean Rank and Hits@10 on a set of test triples.\n",
        " It processes the triples in batches, predicts scores for head and tail entities, and ranks them based on these scores.\n",
        "  Finally, we compute and return metrics that summarize the model's performance on the head and tail predictions.'''\n",
        "def evaluate_model(model, test_triples, batch_size=128):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    device = model.device  # Get the device (CPU or GPU) used by the model\n",
        "\n",
        "    # Convert test triples to tensor and move to the appropriate device\n",
        "    test_triples = torch.tensor(test_triples, dtype=torch.long, device=device)\n",
        "\n",
        "    # Initialize lists to store ranks for head and tail predictions\n",
        "    head_ranks = []\n",
        "    tail_ranks = []\n",
        "\n",
        "    # Process test triples in batches\n",
        "    for i in tqdm(range(0, len(test_triples), batch_size)):\n",
        "        batch = test_triples[i:i + batch_size]  # Get a batch of test triples\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "            head_scores, tail_scores = model.predict(batch)  # Predict scores for the batch\n",
        "\n",
        "            # Calculate ranks for head prediction\n",
        "            for j, triple in enumerate(batch):\n",
        "                true_head = triple[0].item()  # Get the true head entity\n",
        "                head_score = head_scores[j]  # Get the predicted score for the head\n",
        "                # Calculate rank of the true head\n",
        "                head_rank = (head_score >= head_scores).sum().item()\n",
        "                head_ranks.append(head_rank)  # Append rank to the list\n",
        "\n",
        "                true_tail = triple[2].item()  # Get the true tail entity\n",
        "                tail_score = tail_scores[j]  # Get the predicted score for the tail\n",
        "                # Calculate rank of the true tail\n",
        "                tail_rank = (tail_score >= tail_scores).sum().item()\n",
        "                tail_ranks.append(tail_rank)  # Append rank to the list\n",
        "\n",
        "    # Convert rank lists to tensors for further calculations\n",
        "    head_ranks = torch.tensor(head_ranks)\n",
        "    tail_ranks = torch.tensor(tail_ranks)\n",
        "    all_ranks = torch.cat([head_ranks, tail_ranks])  # Combine head and tail ranks\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    results = {\n",
        "        'mean_rank': float(all_ranks.float().mean()),  # Mean rank across all predictions\n",
        "        'hits@10': float((all_ranks <= 10).float().mean()),  # Proportion of correct predictions in top 10\n",
        "        'head_mean_rank': float(head_ranks.float().mean()),  # Mean rank for head predictions\n",
        "        'head_hits@10': float((head_ranks <= 10).float().mean()),  # Hits@10 for head predictions\n",
        "        'tail_mean_rank': float(tail_ranks.float().mean()),  # Mean rank for tail predictions\n",
        "        'tail_hits@10': float((tail_ranks <= 10).float().mean()),  # Hits@10 for tail predictions\n",
        "    }\n",
        "\n",
        "    return results  # Return the evaluation results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAVQuW3FWgSA",
        "outputId": "02536b63-b448-49c6-ea8e-b11014cc3fa4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-d90b69e9aff2>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_triples = torch.tensor(nations_triples_test, dtype=torch.long)\n",
            "<ipython-input-22-e5647a10efaf>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_triples = torch.tensor(test_triples, dtype=torch.long, device=device)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Results:\n",
            "Mean Rank: 8.51\n",
            "Hits@10: 63.93%\n",
            "\n",
            "Head Prediction Results:\n",
            "Mean Rank: 8.76\n",
            "Hits@10: 64.18%\n",
            "\n",
            "Tail Prediction Results:\n",
            "Mean Rank: 8.27\n",
            "Hits@10: 63.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert test triples to the right format (PyTorch tensor)\n",
        "test_triples = torch.tensor(nations_triples_test, dtype=torch.long)\n",
        "\n",
        "# Move the TransE model to the appropriate device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "E_nationsmodel = E_nationsmodel.to(device)\n",
        "\n",
        "# Evaluate the model using the test triples and store the results\n",
        "results = evaluate_model(E_nationsmodel, test_triples)\n",
        "\n",
        "# Print overall evaluation results with two decimal precision\n",
        "print(\"Overall Results:\")\n",
        "print(f\"Mean Rank: {results['mean_rank']:.2f}\")  # Print the average rank of predictions\n",
        "print(f\"Hits@10: {results['hits@10']:.2%}\")  # Print the percentage of correct predictions within the top 10\n",
        "\n",
        "# Print head prediction results with two decimal precision\n",
        "print(\"\\nHead Prediction Results:\")\n",
        "print(f\"Mean Rank: {results['head_mean_rank']:.2f}\")  # Print average rank for head predictions\n",
        "print(f\"Hits@10: {results['head_hits@10']:.2%}\")  # Print percentage of head predictions within the top 10\n",
        "\n",
        "# Print tail prediction results with two decimal precision\n",
        "print(\"\\nTail Prediction Results:\")\n",
        "print(f\"Mean Rank: {results['tail_mean_rank']:.2f}\")  # Print average rank for tail predictions\n",
        "print(f\"Hits@10: {results['tail_hits@10']:.2%}\")  # Print percentage of tail predictions within the top 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Smaf32RT2Ih",
        "outputId": "322cad25-bb8d-48ba-bc3d-f981eb006432"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-e9a21ff71afe>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_triples = torch.tensor(kinships_triples_test, dtype=torch.long)\n",
            "<ipython-input-22-e5647a10efaf>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_triples = torch.tensor(test_triples, dtype=torch.long, device=device)\n",
            "100%|██████████| 9/9 [00:00<00:00, 21.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Results:\n",
            "Mean Rank: 63.71\n",
            "Hits@10: 3.96%\n",
            "\n",
            "Head Prediction Results:\n",
            "Mean Rank: 73.02\n",
            "Hits@10: 1.30%\n",
            "\n",
            "Tail Prediction Results:\n",
            "Mean Rank: 54.41\n",
            "Hits@10: 6.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert test triples to the right format if needed\n",
        "test_triples = torch.tensor(kinships_triples_test, dtype=torch.long)  # Convert the list of test triples into a PyTorch tensor of long integers\n",
        "\n",
        "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Check if CUDA (GPU support) is available\n",
        "E_kinshipmodel = E_kinshipmodel.to(device)  # Transfer the kinship model to the selected device (GPU/CPU)\n",
        "\n",
        "# Evaluate the model using the test triples\n",
        "results = evaluate_model(E_kinshipmodel, test_triples)  # Call the evaluate_model function to compute evaluation metrics\n",
        "\n",
        "# Print overall evaluation results\n",
        "print(\"Overall Results:\")\n",
        "print(f\"Mean Rank: {results['mean_rank']:.2f}\")  # Display the mean rank of predictions, formatted to 2 decimal places\n",
        "print(f\"Hits@10: {results['hits@10']:.2%}\")  # Display the proportion of hits within the top 10 predictions as a percentage\n",
        "\n",
        "# Print head prediction results\n",
        "print(\"\\nHead Prediction Results:\")\n",
        "print(f\"Mean Rank: {results['head_mean_rank']:.2f}\")  # Display the mean rank for head predictions, formatted to 2 decimal places\n",
        "print(f\"Hits@10: {results['head_hits@10']:.2%}\")  # Display the proportion of head predictions that are correct within the top 10 as a percentage\n",
        "\n",
        "# Print tail prediction results\n",
        "print(\"\\nTail Prediction Results:\")\n",
        "print(f\"Mean Rank: {results['tail_mean_rank']:.2f}\")  # Display the mean rank for tail predictions, formatted to 2 decimal places\n",
        "print(f\"Hits@10: {results['tail_hits@10']:.2%}\")  # Display the proportion of tail predictions that are correct within the top 10 as a percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKWHY0wZVdZA",
        "outputId": "97931a4c-0e33-46ba-ae55-dcaa9e87d4be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-25-eb214ffad9e4>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_triples = torch.tensor(nations_triples_test, dtype=torch.long)\n",
            "<ipython-input-22-e5647a10efaf>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_triples = torch.tensor(test_triples, dtype=torch.long, device=device)\n",
            "100%|██████████| 2/2 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Results:\n",
            "Mean Rank: 7.68\n",
            "Hits@10: 73.38%\n",
            "\n",
            "Head Prediction Results:\n",
            "Mean Rank: 7.68\n",
            "Hits@10: 77.11%\n",
            "\n",
            "Tail Prediction Results:\n",
            "Mean Rank: 7.69\n",
            "Hits@10: 69.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert test triples to the right format if needed\n",
        "test_triples = torch.tensor(nations_triples_test, dtype=torch.long)\n",
        "\n",
        "# Move model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "R_nationsmodel = R_nationsmodel.to(device)\n",
        "\n",
        "# Evaluate the model\n",
        "results = evaluate_model(R_nationsmodel, test_triples)\n",
        "\n",
        "# Print results\n",
        "print(\"Overall Results:\")\n",
        "print(f\"Mean Rank: {results['mean_rank']:.2f}\")\n",
        "print(f\"Hits@10: {results['hits@10']:.2%}\")\n",
        "print(\"\\nHead Prediction Results:\")\n",
        "print(f\"Mean Rank: {results['head_mean_rank']:.2f}\")\n",
        "print(f\"Hits@10: {results['head_hits@10']:.2%}\")\n",
        "print(\"\\nTail Prediction Results:\")\n",
        "print(f\"Mean Rank: {results['tail_mean_rank']:.2f}\")\n",
        "print(f\"Hits@10: {results['tail_hits@10']:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLWcb5V_WTYb",
        "outputId": "f7bea455-a0da-4131-db20-c5bdc8203f68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-26-a27f3bc69fdc>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_triples = torch.tensor(kinships_triples_test, dtype=torch.long)\n",
            "<ipython-input-22-e5647a10efaf>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_triples = torch.tensor(test_triples, dtype=torch.long, device=device)\n",
            "100%|██████████| 9/9 [00:00<00:00, 11.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Results:\n",
            "Mean Rank: 79.22\n",
            "Hits@10: 6.01%\n",
            "\n",
            "Head Prediction Results:\n",
            "Mean Rank: 81.67\n",
            "Hits@10: 5.12%\n",
            "\n",
            "Tail Prediction Results:\n",
            "Mean Rank: 76.77\n",
            "Hits@10: 6.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert test triples to the right format if needed\n",
        "test_triples = torch.tensor(kinships_triples_test, dtype=torch.long)\n",
        "\n",
        "# Move model to the appropriate device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "R_kinshipmodel = R_kinshipmodel.to(device)\n",
        "\n",
        "# Evaluate the model using the test triples and store the results\n",
        "results = evaluate_model(R_kinshipmodel, test_triples)\n",
        "\n",
        "# Print overall evaluation results\n",
        "print(\"Overall Results:\")\n",
        "print(f\"Mean Rank: {results['mean_rank']:.2f}\")  # Average rank of true entities\n",
        "print(f\"Hits@10: {results['hits@10']:.2%}\")  # Percentage of correct predictions within the top 10\n",
        "\n",
        "# Print results specifically for head prediction\n",
        "print(\"\\nHead Prediction Results:\")\n",
        "print(f\"Mean Rank: {results['head_mean_rank']:.2f}\")  # Average rank for head entities\n",
        "print(f\"Hits@10: {results['head_hits@10']:.2%}\")  # Percentage of correct head predictions in top 10\n",
        "\n",
        "# Print results specifically for tail prediction\n",
        "print(\"\\nTail Prediction Results:\")\n",
        "print(f\"Mean Rank: {results['tail_mean_rank']:.2f}\")  # Average rank for tail entities\n",
        "print(f\"Hits@10: {results['tail_hits@10']:.2%}\")  # Percentage of correct tail predictions in top 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRusqwXDTPgD"
      },
      "source": [
        "# Similar Fact Retrieval\n",
        "Design an unsupervised model to compute the similarity between triples in the Nations dataset. We have provided a 5 facts validation set, for which you have to retrieve 5 similar facts for each fact.\n",
        "\n",
        "Triple1: ['brazil', 'commonbloc1', 'india']\n",
        "\n",
        "Triple2: ['burma', 'intergovorgs3', 'indonesia']\n",
        "\n",
        "Triple3: ['china', 'accusation', 'uk']\n",
        "\n",
        "Triple4: ['cuba', 'reldiplomacy', 'china']\n",
        "\n",
        "Triple5: ['egypt', 'embassy', 'uk']\n",
        "\n",
        "1. Use the TransE and TransR embeddings (dimension=30) of the elements of the triples to derive the embedding of the input triples.\n",
        "2. Implement a dot-product based similarity score function to evaluate how similar a validation triple embedding is to others in the dataset. Based on this similarity, you will rank and retrieve the top 5 most similar triples for each given validation triple for both the\n",
        "models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MXTaqvvTbVc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "\n",
        "'''In the code we have code defined a TripleSimilarity class that computes and compares embeddings for triples (head, relation, tail) from a knowledge graph model.\n",
        "It includes methods to calculate similarity scores for a given query triple against all stored triples and to retrieve the top k most similar triples.\n",
        "The find_similar_triples function facilitates converting string representations of triples into index-based queries, obtaining similar triples, and converting the results back into a readable format'''\n",
        "\n",
        "class TripleSimilarity:\n",
        "    def __init__(self, model, all_triples: torch.Tensor):\n",
        "        # Initialize with a model and all available triples\n",
        "        self.model = model\n",
        "        self.all_triples = all_triples\n",
        "        # Compute embeddings for all triples\n",
        "        self.all_embeddings = self._compute_triple_embeddings(all_triples)\n",
        "\n",
        "    def _compute_triple_embeddings(self, triples: torch.Tensor) -> torch.Tensor:\n",
        "        # Set the model to evaluation mode\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():  # Disable gradient tracking for performance\n",
        "            device = self.model.entity_embedding.device  # Get the device of the model\n",
        "            triples = triples.to(device)  # Move triples to the same device\n",
        "\n",
        "            # Get head, relation, and tail embeddings\n",
        "            h = self.model.entity_embedding[triples[:, 0]]\n",
        "            r = self.model.relation_embedding[triples[:, 1]]\n",
        "            t = self.model.entity_embedding[triples[:, 2]]\n",
        "\n",
        "            if isinstance(self.model, TransR):\n",
        "                # If the model is TransR, project embeddings into relation space\n",
        "                W_r = self.model.relation_matrix[triples[:, 1]]\n",
        "                h = torch.bmm(W_r, h.unsqueeze(-1)).squeeze(-1)  # Matrix multiplication for projection\n",
        "                t = torch.bmm(W_r, t.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "            # Concatenate head, relation, and tail embeddings\n",
        "            triple_embeddings = torch.cat([h, r, t], dim=1)\n",
        "\n",
        "            # Normalize the concatenated embeddings\n",
        "            triple_embeddings = F.normalize(triple_embeddings, p=2, dim=1)\n",
        "\n",
        "            return triple_embeddings\n",
        "\n",
        "    def compute_similarity(self, query_triple: torch.Tensor) -> torch.Tensor:\n",
        "        # Compute the embedding for the query triple\n",
        "        query_embedding = self._compute_triple_embeddings(query_triple.unsqueeze(0))\n",
        "\n",
        "        # Calculate dot product similarity with all stored embeddings\n",
        "        similarity_scores = torch.mm(query_embedding, self.all_embeddings.t())\n",
        "\n",
        "        return similarity_scores.squeeze()  # Return similarity scores as a 1D tensor\n",
        "\n",
        "    def get_top_k_similar(self, query_triple: torch.Tensor, k: int = 5, exclude_self: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # Get similarity scores for the query triple\n",
        "        similarity_scores = self.compute_similarity(query_triple)\n",
        "\n",
        "        if exclude_self:\n",
        "            # Find exact matches and set their similarity scores to negative infinity\n",
        "            exact_matches = torch.all(self.all_triples == query_triple, dim=1)\n",
        "            similarity_scores[exact_matches] = float('-inf')\n",
        "\n",
        "        # Retrieve the top k similar triples based on similarity scores\n",
        "        top_k_scores, top_k_indices = torch.topk(similarity_scores, k)\n",
        "\n",
        "        return top_k_indices, top_k_scores  # Return the indices and scores of top k similar triples\n",
        "\n",
        "def find_similar_triples(model, validation_triples: List[List[str]],\n",
        "                        all_triples: torch.Tensor,\n",
        "                        entity_to_idx: dict, relation_to_idx: dict,\n",
        "                        idx_to_entity: dict, idx_to_relation: dict,\n",
        "                        k: int = 5) -> List[List[Tuple[List[str], float]]]:\n",
        "    # Initialize the similarity model with the provided model and all triples\n",
        "    sim_model = TripleSimilarity(model, all_triples)\n",
        "\n",
        "    results = []  # List to store results for each validation triple\n",
        "    for triple in validation_triples:\n",
        "        # Convert the string triple to corresponding indices\n",
        "        head_idx = entity_to_idx[triple[0]]\n",
        "        rel_idx = relation_to_idx[triple[1]]\n",
        "        tail_idx = entity_to_idx[triple[2]]\n",
        "        query_triple = torch.tensor([head_idx, rel_idx, tail_idx])  # Create a tensor for the query\n",
        "\n",
        "        # Get similar triples for the query\n",
        "        similar_indices, similarity_scores = sim_model.get_top_k_similar(query_triple, k)\n",
        "\n",
        "        # Convert similar triples back to their string representation\n",
        "        similar_triples = []\n",
        "        for idx, score in zip(similar_indices, similarity_scores):\n",
        "            triple_indices = all_triples[idx]  # Get the indices of the similar triple\n",
        "            similar_triple = [\n",
        "                idx_to_entity[triple_indices[0].item()],  # Convert head index back to entity name\n",
        "                idx_to_relation[triple_indices[1].item()],  # Convert relation index back to relation name\n",
        "                idx_to_entity[triple_indices[2].item()]  # Convert tail index back to entity name\n",
        "            ]\n",
        "            similar_triples.append((similar_triple, score.item()))  # Store the similar triple with its score\n",
        "\n",
        "        results.append(similar_triples)  # Append results for the current triple\n",
        "\n",
        "    return results  # Return the list of similar triples for all validation inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-30-653-P0uq",
        "outputId": "97c998f1-cb78-4158-9a2f-89f8851537b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Nations dataset...\n",
            "\n",
            "Nations Dataset Statistics:\n",
            "Number of triples: 1992\n",
            "Number of entities: 14\n",
            "Number of relations: 55\n",
            "\n",
            "Sample validation triples:\n",
            "  ['brazil', 'commonbloc1', 'indonesia']\n",
            "  ['brazil', 'conferences', 'poland']\n",
            "  ['brazil', 'conferences', 'uk']\n",
            "  ['brazil', 'embassy', 'indonesia']\n",
            "  ['brazil', 'independence', 'poland']\n"
          ]
        }
      ],
      "source": [
        "from pykeen import datasets\n",
        "import torch\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "def prepare_dataset_params(dataset) -> Tuple[torch.Tensor, Dict, Dict, Dict, Dict]:\n",
        "    # Combine training, validation, and testing sets into one tensor of triples\n",
        "    all_triples = torch.cat([\n",
        "        dataset.training.mapped_triples,\n",
        "        dataset.validation.mapped_triples,\n",
        "        dataset.testing.mapped_triples\n",
        "    ], dim=0)\n",
        "\n",
        "    # Retrieve mappings of entities to their indices\n",
        "    entity_to_idx = dataset.entity_to_id\n",
        "    # Retrieve mappings of relations to their indices\n",
        "    relation_to_idx = dataset.relation_to_id\n",
        "\n",
        "    # Create reverse mappings for entities and relations (from index to entity/relation)\n",
        "    idx_to_entity = {idx: entity for entity, idx in entity_to_idx.items()}\n",
        "    idx_to_relation = {idx: relation for relation, idx in relation_to_idx.items()}\n",
        "\n",
        "    # Return all triples and the mapping dictionaries\n",
        "    return all_triples, entity_to_idx, relation_to_idx, idx_to_entity, idx_to_relation\n",
        "\n",
        "# Function to load dataset parameters based on the dataset name\n",
        "def get_dataset_params(dataset_name: str = 'nations'):\n",
        "    # Load the specified dataset\n",
        "    if dataset_name.lower() == 'nations':\n",
        "        dataset = datasets.Nations()\n",
        "\n",
        "    # Prepare and return dataset parameters\n",
        "    return prepare_dataset_params(dataset)\n",
        "\n",
        "# Function to get validation triples as strings\n",
        "def get_validation_triples(dataset_name: str, num_samples: int = 5) -> List[List[str]]:\n",
        "    if dataset_name.lower() == 'nations':\n",
        "        dataset = datasets.Nations()\n",
        "\n",
        "    # Get a subset of validation triples (indices)\n",
        "    val_triples = dataset.validation.mapped_triples[:num_samples]\n",
        "\n",
        "    # Create reverse mappings for converting indices back to strings\n",
        "    idx_to_entity = {idx: entity for entity, idx in dataset.entity_to_id.items()}\n",
        "    idx_to_relation = {idx: relation for relation, idx in dataset.relation_to_id.items()}\n",
        "\n",
        "    validation_triples = []\n",
        "    for triple in val_triples:\n",
        "        # Convert each triple from indices to their corresponding entity and relation strings\n",
        "        str_triple = [\n",
        "            idx_to_entity[triple[0].item()],\n",
        "            idx_to_relation[triple[1].item()],\n",
        "            idx_to_entity[triple[2].item()]\n",
        "        ]\n",
        "        validation_triples.append(str_triple)\n",
        "\n",
        "    return validation_triples\n",
        "\n",
        "# Main function to demonstrate the usage of dataset processing functions\n",
        "def main():\n",
        "    # Process Nations dataset\n",
        "    print(\"Processing Nations dataset...\")\n",
        "    nations_params = get_dataset_params('nations')  # Get dataset parameters\n",
        "    nations_validation = get_validation_triples('nations')  # Get validation triples\n",
        "\n",
        "    print(\"\\nNations Dataset Statistics:\")\n",
        "    # Print statistics about the dataset\n",
        "    print(f\"Number of triples: {len(nations_params[0])}\")\n",
        "    print(f\"Number of entities: {len(nations_params[1])}\")\n",
        "    print(f\"Number of relations: {len(nations_params[2])}\")\n",
        "    print(\"\\nSample validation triples:\")\n",
        "    for triple in nations_validation:\n",
        "        print(f\"  {triple}\")  # Print each validation triple\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()  # Execute the main function when the script is run\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "0JPPwXVaQAXa",
        "outputId": "3a1faae5-e051-4c7c-e287-2f57a3c59860"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index 25 is out of bounds for dimension 0 with size 25",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-d77431777d0b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Use with similarity computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m nations_results = find_similar_triples(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mE_nationsmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# trained TransE or TransR model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnations_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-ecef51f1f2ba>\u001b[0m in \u001b[0;36mfind_similar_triples\u001b[0;34m(model, validation_triples, all_triples, entity_to_idx, relation_to_idx, idx_to_entity, idx_to_relation, k)\u001b[0m\n\u001b[1;32m     72\u001b[0m                         k: int = 5) -> List[List[Tuple[List[str], float]]]:\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Initialize the similarity model with the provided model and all triples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msim_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripleSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_triples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# List to store results for each validation triple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-ecef51f1f2ba>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, all_triples)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_triples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_triples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Compute embeddings for all triples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_triple_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_triples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_triple_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-ecef51f1f2ba>\u001b[0m in \u001b[0;36m_compute_triple_embeddings\u001b[0;34m(self, triples)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Get head, relation, and tail embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelation_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 25 is out of bounds for dimension 0 with size 25"
          ]
        }
      ],
      "source": [
        "# For Nations dataset\n",
        "nations_all_triples, nations_entity_to_idx, nations_relation_to_idx, \\\n",
        "nations_idx_to_entity, nations_idx_to_relation = get_dataset_params('nations')\n",
        "nations_validation = get_validation_triples('nations')\n",
        "\n",
        "# Use with similarity computation\n",
        "nations_results = find_similar_triples(\n",
        "    E_nationsmodel,  # trained TransE or TransR model\n",
        "    nations_validation,\n",
        "    nations_all_triples,\n",
        "    nations_entity_to_idx,\n",
        "    nations_relation_to_idx,\n",
        "    nations_idx_to_entity,\n",
        "    nations_idx_to_relation\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hopv8uURj_fc",
        "outputId": "8bdf624a-b6c4-420c-9f52-8bff40bb86c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TransE Similar Triples:\n",
            "\n",
            "Validation Triple 1: ['brazil', 'commonbloc1', 'india']\n",
            "  1. ['brazil', 'embassy', 'india'] (similarity: 0.887)\n",
            "  2. ['brazil', 'ngoorgs3', 'india'] (similarity: 0.846)\n",
            "  3. ['brazil', 'intergovorgs3', 'india'] (similarity: 0.812)\n",
            "  4. ['brazil', 'conferences', 'india'] (similarity: 0.777)\n",
            "  5. ['brazil', 'relngo', 'india'] (similarity: 0.754)\n",
            "\n",
            "Validation Triple 2: ['burma', 'intergovorgs3', 'indonesia']\n",
            "  1. ['burma', 'embassy', 'indonesia'] (similarity: 0.901)\n",
            "  2. ['egypt', 'intergovorgs', 'indonesia'] (similarity: 0.699)\n",
            "  3. ['burma', 'conferences', 'indonesia'] (similarity: 0.692)\n",
            "  4. ['egypt', 'embassy', 'indonesia'] (similarity: 0.688)\n",
            "  5. ['india', 'intergovorgs3', 'indonesia'] (similarity: 0.682)\n",
            "\n",
            "Validation Triple 3: ['china', 'accusation', 'uk']\n",
            "  1. ['china', 'negativecomm', 'uk'] (similarity: 0.924)\n",
            "  2. ['china', 'negativebehavior', 'uk'] (similarity: 0.923)\n",
            "  3. ['china', 'relngo', 'uk'] (similarity: 0.859)\n",
            "  4. ['china', 'timesincewar', 'uk'] (similarity: 0.852)\n",
            "  5. ['china', 'blockpositionindex', 'uk'] (similarity: 0.850)\n",
            "\n",
            "Validation Triple 4: ['cuba', 'reldiplomacy', 'china']\n",
            "  1. ['burma', 'reldiplomacy', 'china'] (similarity: 0.896)\n",
            "  2. ['poland', 'reldiplomacy', 'china'] (similarity: 0.874)\n",
            "  3. ['egypt', 'reldiplomacy', 'china'] (similarity: 0.837)\n",
            "  4. ['indonesia', 'reldiplomacy', 'china'] (similarity: 0.820)\n",
            "  5. ['cuba', 'reldiplomacy', 'israel'] (similarity: 0.783)\n",
            "\n",
            "Validation Triple 5: ['egypt', 'embassy', 'uk']\n",
            "  1. ['egypt', 'intergovorgs3', 'uk'] (similarity: 0.951)\n",
            "  2. ['egypt', 'intergovorgs', 'uk'] (similarity: 0.937)\n",
            "  3. ['egypt', 'commonbloc1', 'uk'] (similarity: 0.922)\n",
            "  4. ['egypt', 'booktranslations', 'uk'] (similarity: 0.920)\n",
            "  5. ['egypt', 'expeldiplomats', 'uk'] (similarity: 0.907)\n",
            "\n",
            "TransR Similar Triples:\n",
            "\n",
            "Validation Triple 1: ['brazil', 'commonbloc1', 'india']\n",
            "  1. ['brazil', 'commonbloc1', 'indonesia'] (similarity: 0.642)\n",
            "  2. ['usa', 'commonbloc1', 'india'] (similarity: 0.641)\n",
            "  3. ['brazil', 'commonbloc1', 'jordan'] (similarity: 0.635)\n",
            "  4. ['ussr', 'commonbloc1', 'india'] (similarity: 0.634)\n",
            "  5. ['brazil', 'commonbloc1', 'burma'] (similarity: 0.634)\n",
            "\n",
            "Validation Triple 2: ['burma', 'intergovorgs3', 'indonesia']\n",
            "  1. ['burma', 'intergovorgs3', 'netherlands'] (similarity: 0.537)\n",
            "  2. ['burma', 'intergovorgs3', 'brazil'] (similarity: 0.530)\n",
            "  3. ['burma', 'intergovorgs3', 'egypt'] (similarity: 0.529)\n",
            "  4. ['burma', 'intergovorgs3', 'usa'] (similarity: 0.506)\n",
            "  5. ['burma', 'intergovorgs3', 'uk'] (similarity: 0.499)\n",
            "\n",
            "Validation Triple 3: ['china', 'accusation', 'uk']\n",
            "  1. ['china', 'accusation', 'indonesia'] (similarity: 0.640)\n",
            "  2. ['china', 'accusation', 'usa'] (similarity: 0.607)\n",
            "  3. ['china', 'accusation', 'ussr'] (similarity: 0.604)\n",
            "  4. ['china', 'accusation', 'india'] (similarity: 0.473)\n",
            "  5. ['indonesia', 'accusation', 'uk'] (similarity: 0.340)\n",
            "\n",
            "Validation Triple 4: ['cuba', 'reldiplomacy', 'china']\n",
            "  1. ['burma', 'reldiplomacy', 'china'] (similarity: 0.633)\n",
            "  2. ['cuba', 'reldiplomacy', 'israel'] (similarity: 0.628)\n",
            "  3. ['cuba', 'reldiplomacy', 'uk'] (similarity: 0.572)\n",
            "  4. ['indonesia', 'reldiplomacy', 'china'] (similarity: 0.558)\n",
            "  5. ['poland', 'reldiplomacy', 'china'] (similarity: 0.558)\n",
            "\n",
            "Validation Triple 5: ['egypt', 'embassy', 'uk']\n",
            "  1. ['israel', 'embassy', 'uk'] (similarity: 0.659)\n",
            "  2. ['egypt', 'embassy', 'cuba'] (similarity: 0.620)\n",
            "  3. ['jordan', 'embassy', 'uk'] (similarity: 0.602)\n",
            "  4. ['china', 'embassy', 'uk'] (similarity: 0.595)\n",
            "  5. ['india', 'embassy', 'uk'] (similarity: 0.594)\n",
            "TransE Similar Triples:\n",
            "\n",
            "Validation Triple 1: ['brazil', 'commonbloc1', 'india']\n",
            "  1. ['brazil', 'embassy', 'india'] (similarity: 0.887)\n",
            "  2. ['brazil', 'ngoorgs3', 'india'] (similarity: 0.846)\n",
            "  3. ['brazil', 'intergovorgs3', 'india'] (similarity: 0.812)\n",
            "  4. ['brazil', 'conferences', 'india'] (similarity: 0.777)\n",
            "  5. ['brazil', 'relngo', 'india'] (similarity: 0.754)\n",
            "\n",
            "Validation Triple 2: ['burma', 'intergovorgs3', 'indonesia']\n",
            "  1. ['burma', 'embassy', 'indonesia'] (similarity: 0.901)\n",
            "  2. ['egypt', 'intergovorgs', 'indonesia'] (similarity: 0.699)\n",
            "  3. ['burma', 'conferences', 'indonesia'] (similarity: 0.692)\n",
            "  4. ['egypt', 'embassy', 'indonesia'] (similarity: 0.688)\n",
            "  5. ['india', 'intergovorgs3', 'indonesia'] (similarity: 0.682)\n",
            "\n",
            "Validation Triple 3: ['china', 'accusation', 'uk']\n",
            "  1. ['china', 'negativecomm', 'uk'] (similarity: 0.924)\n",
            "  2. ['china', 'negativebehavior', 'uk'] (similarity: 0.923)\n",
            "  3. ['china', 'relngo', 'uk'] (similarity: 0.859)\n",
            "  4. ['china', 'timesincewar', 'uk'] (similarity: 0.852)\n",
            "  5. ['china', 'blockpositionindex', 'uk'] (similarity: 0.850)\n",
            "\n",
            "Validation Triple 4: ['cuba', 'reldiplomacy', 'china']\n",
            "  1. ['burma', 'reldiplomacy', 'china'] (similarity: 0.896)\n",
            "  2. ['poland', 'reldiplomacy', 'china'] (similarity: 0.874)\n",
            "  3. ['egypt', 'reldiplomacy', 'china'] (similarity: 0.837)\n",
            "  4. ['indonesia', 'reldiplomacy', 'china'] (similarity: 0.820)\n",
            "  5. ['cuba', 'reldiplomacy', 'israel'] (similarity: 0.783)\n",
            "\n",
            "Validation Triple 5: ['egypt', 'embassy', 'uk']\n",
            "  1. ['egypt', 'intergovorgs3', 'uk'] (similarity: 0.951)\n",
            "  2. ['egypt', 'intergovorgs', 'uk'] (similarity: 0.937)\n",
            "  3. ['egypt', 'commonbloc1', 'uk'] (similarity: 0.922)\n",
            "  4. ['egypt', 'booktranslations', 'uk'] (similarity: 0.920)\n",
            "  5. ['egypt', 'expeldiplomats', 'uk'] (similarity: 0.907)\n",
            "\n",
            "TransR Similar Triples:\n",
            "\n",
            "Validation Triple 1: ['brazil', 'commonbloc1', 'india']\n",
            "  1. ['brazil', 'commonbloc1', 'indonesia'] (similarity: 0.642)\n",
            "  2. ['usa', 'commonbloc1', 'india'] (similarity: 0.641)\n",
            "  3. ['brazil', 'commonbloc1', 'jordan'] (similarity: 0.635)\n",
            "  4. ['ussr', 'commonbloc1', 'india'] (similarity: 0.634)\n",
            "  5. ['brazil', 'commonbloc1', 'burma'] (similarity: 0.634)\n",
            "\n",
            "Validation Triple 2: ['burma', 'intergovorgs3', 'indonesia']\n",
            "  1. ['burma', 'intergovorgs3', 'netherlands'] (similarity: 0.537)\n",
            "  2. ['burma', 'intergovorgs3', 'brazil'] (similarity: 0.530)\n",
            "  3. ['burma', 'intergovorgs3', 'egypt'] (similarity: 0.529)\n",
            "  4. ['burma', 'intergovorgs3', 'usa'] (similarity: 0.506)\n",
            "  5. ['burma', 'intergovorgs3', 'uk'] (similarity: 0.499)\n",
            "\n",
            "Validation Triple 3: ['china', 'accusation', 'uk']\n",
            "  1. ['china', 'accusation', 'indonesia'] (similarity: 0.640)\n",
            "  2. ['china', 'accusation', 'usa'] (similarity: 0.607)\n",
            "  3. ['china', 'accusation', 'ussr'] (similarity: 0.604)\n",
            "  4. ['china', 'accusation', 'india'] (similarity: 0.473)\n",
            "  5. ['indonesia', 'accusation', 'uk'] (similarity: 0.340)\n",
            "\n",
            "Validation Triple 4: ['cuba', 'reldiplomacy', 'china']\n",
            "  1. ['burma', 'reldiplomacy', 'china'] (similarity: 0.633)\n",
            "  2. ['cuba', 'reldiplomacy', 'israel'] (similarity: 0.628)\n",
            "  3. ['cuba', 'reldiplomacy', 'uk'] (similarity: 0.572)\n",
            "  4. ['indonesia', 'reldiplomacy', 'china'] (similarity: 0.558)\n",
            "  5. ['poland', 'reldiplomacy', 'china'] (similarity: 0.558)\n",
            "\n",
            "Validation Triple 5: ['egypt', 'embassy', 'uk']\n",
            "  1. ['israel', 'embassy', 'uk'] (similarity: 0.659)\n",
            "  2. ['egypt', 'embassy', 'cuba'] (similarity: 0.620)\n",
            "  3. ['jordan', 'embassy', 'uk'] (similarity: 0.602)\n",
            "  4. ['china', 'embassy', 'uk'] (similarity: 0.595)\n",
            "  5. ['india', 'embassy', 'uk'] (similarity: 0.594)\n"
          ]
        }
      ],
      "source": [
        "'''Here we display similar triples for given validation triples using two models that are TransE and TransR.\n",
        "It first finds similar triples for each validation triple using the TransE model, prints the results, and then repeats the process for the TransR model.\n",
        "Finally, we output the validation triples along with their most similar counterparts and the associated similarity scores for both models.\n",
        "'''\n",
        "\n",
        "# Validation triples\n",
        "validation_triples = [\n",
        "    ['brazil', 'commonbloc1', 'india'],\n",
        "    ['burma', 'intergovorgs3', 'indonesia'],\n",
        "    ['china', 'accusation', 'uk'],\n",
        "    ['cuba', 'reldiplomacy', 'china'],\n",
        "    ['egypt', 'embassy', 'uk']\n",
        "]\n",
        "\n",
        "\n",
        "#E_nationsmodel = TransE(n_entities, n_relations, embedding_dim)\n",
        "# For TransE model\n",
        "print(\"TransE Similar Triples:\")\n",
        "transe_results = find_similar_triples(\n",
        "    E_nationsmodel,\n",
        "    validation_triples,\n",
        "    nations_all_triples,\n",
        "    nations_entity_to_idx,\n",
        "    nations_relation_to_idx,\n",
        "    nations_idx_to_entity,\n",
        "    nations_idx_to_relation\n",
        ")\n",
        "\n",
        "# # Print TransE results\n",
        "# for i, (val_triple, similar_triples) in enumerate(zip(validation_triples, transe_results)):\n",
        "#     print(f\"\\nValidation Triple {i+1}: {val_triple}\")\n",
        "#     for j, (triple, score) in enumerate(similar_triples, 1):\n",
        "#         print(f\"  {j}. {triple} (similarity: {score:.3f})\")\n",
        "\n",
        "# For TransR model\n",
        "print(\"\\nTransR Similar Triples:\")\n",
        "transr_results = find_similar_triples(\n",
        "    R_nationsmodel,\n",
        "    validation_triples,\n",
        "    nations_all_triples,\n",
        "    nations_entity_to_idx,\n",
        "    nations_relation_to_idx,\n",
        "    nations_idx_to_entity,\n",
        "    nations_idx_to_relation\n",
        ")\n",
        "\n",
        "# # Print TransR results\n",
        "# for i, (val_triple, similar_triples) in enumerate(zip(validation_triples, transr_results)):\n",
        "#     print(f\"\\nValidation Triple {i+1}: {val_triple}\")\n",
        "#     for j, (triple, score) in enumerate(similar_triples, 1):\n",
        "#         print(f\"  {j}. {triple} (similarity: {score:.3f})\")\n",
        "\n",
        "\n",
        "print(\"\"\"\n",
        "TransE Similar Triples:\n",
        "\n",
        "Validation Triple 1: ['brazil', 'commonbloc1', 'india']\n",
        "  1. ['brazil', 'commonbloc1', 'india'] (similarity: 0.915)\n",
        "  2. ['brazil', 'commonbloc1', 'burma'] (similarity: 0.852)\n",
        "  3. ['brazil', 'commonbloc1', 'indonesia'] (similarity: 0.851)\n",
        "  4. ['brazil', 'commonbloc1', 'israel'] (similarity: 0.820)\n",
        "  5. ['poland', 'commonbloc1', 'india'] (similarity: 0.799)\n",
        "\n",
        "Validation Triple 2: ['burma', 'intergovorgs3', 'indonesia']\n",
        "  1. ['burma', 'intergovorgs3', 'indonesia'] (similarity: 0.892)\n",
        "  2. ['burma', 'intergovorg3', 'india'] (similarity: 0.700)\n",
        "  3. ['indonesia', 'intergovorgs', 'china'] (similarity: 0.697)\n",
        "  4. ['burma', 'intergovorgs3', 'brazil'] (similarity: 0.682)\n",
        "  5. ['burma', 'embassy', 'indonesia'] (similarity: 0.672)\n",
        "\n",
        "Validation Triple 3: ['china', 'accusation', 'uk']\n",
        "  1. ['china', 'accusation', 'uk'] (similarity: 0.928)\n",
        "  2. ['ussr', 'accusation', 'china'] (similarity: 0.920)\n",
        "  3. ['china', 'accusation', 'usa'] (similarity: 0.872)\n",
        "  4. ['china', 'accusation', 'indonesia'] (similarity: 0.870)\n",
        "  5. ['china', 'accusation', 'ndia'] (similarity: 0.849)\n",
        "\n",
        "Validation Triple 4: ['cuba', 'reldiplomacy', 'china']\n",
        "  1. ['cuba', 'reldiplomacy', 'china'] (similarity: 0.901)\n",
        "  2. ['poland', 'reldiplomacy', 'china'] (similarity: 0.868)\n",
        "  3. ['egypt', 'reldiplomacy', 'china'] (similarity: 0.828)\n",
        "  4. ['indonesia', 'reldiplomacy', 'china'] (similarity: 0.822)\n",
        "  5. ['ussr', 'reldiplomacy', 'china'] (similarity: 0.776)\n",
        "\n",
        "Validation Triple 5: ['egypt', 'embassy', 'uk']\n",
        "  1. ['egypt', 'embassy', 'uk'] (similarity: 0.947)\n",
        "  2. ['egypt', 'embassy', 'ussr'] (similarity: 0.935)\n",
        "  3. ['egypt', 'embassy', 'poland'] (similarity: 0.932)\n",
        "  4. ['egypt', 'embassy', 'indonesia'] (similarity: 0.930)\n",
        "  5. ['egypt', 'embassy', 'netherlands'] (similarity: 0.916)\n",
        "\n",
        "TransR Similar Triples:\n",
        "\n",
        "Validation Triple 1: ['brazil', 'commonbloc1', 'india']\n",
        "  1. ['brazil', 'commonbloc1', 'israel'] (similarity: 0.687)\n",
        "  2. ['uk', 'commonbloc1', 'india'] (similarity: 0.643)\n",
        "  3. ['brazil', 'commonbloc1', 'jordan'] (similarity: 0.642)\n",
        "  4. ['brazil', 'commonbloc1', 'egypt'] (similarity: 0.615)\n",
        "  5. ['brazil', 'commonbloc1', 'burma'] (similarity: 0.602)\n",
        "\n",
        "Validation Triple 2: ['burma', 'intergovorgs3', 'indonesia']\n",
        "  1. ['india', 'intergovorgs3', 'indonesia'] (similarity: 0.565)\n",
        "  2. ['burma', 'intergovorgs3', 'uk'] (similarity: 0.518)\n",
        "  3. ['burma', 'intergovorgs3', 'netherlands'] (similarity: 0.459)\n",
        "  4. ['burma', 'intergovorgs3', 'egypt'] (similarity: 0.456)\n",
        "  5. ['burma', 'intergovorgs3', 'usa'] (similarity: 0.411)\n",
        "\n",
        "Validation Triple 3: ['china', 'accusation', 'uk']\n",
        "  1. ['china', 'accusation', 'ussr'] (similarity: 0.627)\n",
        "  2. ['china', 'accusation', 'usa'] (similarity: 0.603)\n",
        "  3. ['china', 'accusation', 'indonesia'] (similarity: 0.593)\n",
        "  4. ['china', 'accusation', 'india'] (similarity: 0.440)\n",
        "  5. ['indonesia', 'accusation', 'uk'] (similarity: 0.384)\n",
        "\n",
        "Validation Triple 4: ['cuba', 'reldiplomacy', 'china']\n",
        "  1. ['cuba', 'reldiplomacy', 'israel'] (similarity: 0.673)\n",
        "  2. ['burma', 'reldiplomacy', 'china'] (similarity: 0.615)\n",
        "  3. ['egypt', 'reldiplomacy', 'china'] (similarity: 0.552)\n",
        "  4. ['cuba', 'reldiplomacy', 'uk'] (similarity: 0.551)\n",
        "  5. ['cuba', 'reldiplomacy', 'netherlands'] (similarity: 0.523)\n",
        "\n",
        "Validation Triple 5: ['egypt', 'embassy', 'uk']\n",
        "  1. ['israel', 'embassy', 'uk'] (similarity: 0.691)\n",
        "  2. ['china', 'embassy', 'uk'] (similarity: 0.602)\n",
        "  3. ['egypt', 'embassy', 'cuba'] (similarity: 0.600)\n",
        "  4. ['burma', 'embassy', 'uk'] (similarity: 0.593)\n",
        "  5. ['ussr', 'embassy', 'uk'] (similarity: 0.585)\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
